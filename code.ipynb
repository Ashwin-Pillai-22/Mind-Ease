{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90b7221f-ad69-4d24-a662-5ab9dd71b069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "             Mild       1.00      1.00      1.00         5\n",
      "          Minimal       1.00      1.00      1.00         6\n",
      "         Moderate       1.00      1.00      1.00         9\n",
      "Moderately Severe       1.00      1.00      1.00        11\n",
      "           Severe       1.00      1.00      1.00        19\n",
      "\n",
      "         accuracy                           1.00        50\n",
      "        macro avg       1.00      1.00      1.00        50\n",
      "     weighted avg       1.00      1.00      1.00        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "import re\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_excel(\"PHQ9_Student_Depression_Dataset_Updated.xlsx\")\n",
    "\n",
    "# Combine all PHQ9 answers into one text\n",
    "df['combined_text'] = df.iloc[:, 1:11].apply(lambda x: ' '.join(x.dropna().astype(str)), axis=1)\n",
    "df['combined_text'] = df['combined_text'].apply(lambda x: re.sub(r'[^a-zA-Z\\s]', '', x.lower()))\n",
    "\n",
    "# Encode Severity Level\n",
    "le = LabelEncoder()\n",
    "df['label'] = le.fit_transform(df['Severity Level'])\n",
    "\n",
    "# Load pre-trained BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "bert_model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Convert text to BERT embeddings\n",
    "def get_bert_embedding(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = bert_model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
    "\n",
    "# Create embeddings\n",
    "embeddings = np.stack(df['combined_text'].apply(get_bert_embedding).values)\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(embeddings, df['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Random Forest classifier\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names=le.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58b2ce80-7174-4b76-8bd0-44256cb5051d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['label_encoder.pkl']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(clf, \"bert_rf_model.pkl\")\n",
    "joblib.dump(le, \"label_encoder.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6d9189c-6f92-424c-967f-04061b0e2b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.02315622  0.13593969  0.27234566 ... -0.1625643  -0.06535875\n",
      "  -0.26565418]\n",
      " [ 0.09229317  0.09208242  0.13666631 ... -0.05577538  0.00715546\n",
      "  -0.17037666]\n",
      " [-0.3104102   0.18086855  0.45210716 ... -0.1806463   0.11102752\n",
      "  -0.14592333]\n",
      " ...\n",
      " [ 0.04119097 -0.04306969  0.2966259  ... -0.04961918  0.04527418\n",
      "  -0.1550191 ]\n",
      " [-0.02671829  0.05145797  0.1348214  ... -0.11044373  0.07188667\n",
      "  -0.08782027]\n",
      " [ 0.02813066  0.20905516  0.28225234 ... -0.22059192  0.07705928\n",
      "  -0.1026603 ]]\n"
     ]
    }
   ],
   "source": [
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e5123d-eb45-4ca8-bcd4-a62e29c8d0d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ§  Please answer the following PHQ-9 questions:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import torch\n",
    "import joblib\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "# Load saved classifier and label encoder\n",
    "clf = joblib.load(\"bert_rf_model.pkl\")\n",
    "label_encoder = joblib.load(\"label_encoder.pkl\")\n",
    "\n",
    "# Load BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "bert_model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# PHQ-9 Questions\n",
    "phq9_questions = [\n",
    "    \"1. Little interest or pleasure in doing things:\",\n",
    "    \"2. Feeling down, depressed, or hopeless:\",\n",
    "    \"3. Trouble falling or staying asleep, or sleeping too much:\",\n",
    "    \"4. Feeling tired or having little energy:\",\n",
    "    \"5. Poor appetite or overeating:\",\n",
    "    \"6. Feeling bad about yourself â€” or that you are a failure or have let yourself or your family down:\",\n",
    "    \"7. Trouble concentrating on things, such as reading the newspaper or watching television:\",\n",
    "    \"8. Moving or speaking slowly or being restless more than usual:\",\n",
    "    \"9. Thoughts that you would be better off dead or of hurting yourself in some way:\"\n",
    "]\n",
    "\n",
    "# Function to get BERT embedding\n",
    "def get_bert_embedding(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = bert_model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).squeeze().numpy().reshape(1, -1)\n",
    "\n",
    "# Predict from user input\n",
    "def predict_severity():\n",
    "    print(\"\\nðŸ§  Please answer the following PHQ-9 questions:\\n\")\n",
    "    responses = [input(q + \" \") for q in phq9_questions]\n",
    "    combined_text = \" \".join(responses)\n",
    "    cleaned_text = re.sub(r\"[^a-zA-Z\\s]\", \"\", combined_text.lower())\n",
    "    \n",
    "    embedding = get_bert_embedding(cleaned_text)\n",
    "    pred_label = clf.predict(embedding)[0]\n",
    "    severity = label_encoder.inverse_transform([pred_label])[0]\n",
    "    \n",
    "    print(f\"\\nðŸ“Š Predicted Depression Severity: **{severity}**\")\n",
    "\n",
    "# Run the function\n",
    "predict_severity()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2da377e-309e-4104-be72-8401ef4c3bbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbf91fe-a764-4682-9c1e-1fc063d54179",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
